{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51515061-2e5c-4156-9abd-dc586ed2db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from llms import gemini\n",
    "from llms import chatGPT\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plotting\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.utils import ImageReader\n",
    "import plotly.io as pio\n",
    "import requests\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "\n",
    "load_dotenv(\"../.env\",override=True)\n",
    "GEO_KEY = getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "x_chat = chatGPT()\n",
    "x_gemini = gemini()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70f05d31-a8d6-45bc-a67e-dad5f4072555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../output/bls_df.csv\",index_col=0)\n",
    "# tsne = pd.read_csv(\"../output/tsne.csv\",index_col=0)\n",
    "# df = pd.concat([df,tsne],axis=1)\n",
    "\n",
    "# df.example_task_embedding = df.example_task_embedding.apply(lambda x: [float(y) for y in x.strip(\"[]\").split(\", \")])\n",
    "# df.onet_task_embedding = df.onet_task_embedding.apply(lambda x: [float(y) for y in x.strip(\"[]\").split(\", \")])\n",
    "# df.onet_title_embedding = df.onet_title_embedding.apply(lambda x: [float(y) for y in x.strip(\"[]\").split(\", \")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80ca9ad-9524-4f8c-8fd7-51ab7e23e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wage_employment = pd.read_csv(\"../input/wage_employment_2022/national2022.csv\")\n",
    "wage_employment = wage_employment[wage_employment.O_GROUP == \"detailed\"]\n",
    "wage_employment = wage_employment.rename({\"OCC_CODE\": \"Detailed Occupation\"}, axis=1)\n",
    "wage_employment = wage_employment.replace(\"#\", np.nan).replace(\"*\", np.nan).replace({\",\": \"\"}, regex=True)\n",
    "wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]] = wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]].astype(\"float\")\n",
    "wage_employment[\"H_MEDIAN\"] = wage_employment[\"H_MEDIAN\"].round(0)\n",
    "wage_employment = wage_employment[[\"Detailed Occupation\",\"H_MEDIAN\",\"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]]\n",
    "wage_employment.columns = [\"Detailed Occupation\",\"H_MEDIAN_US\",\"A_MEDIAN_US\",\"TOT_EMP_US\",\"JOBS_1000_US\"]\n",
    "\n",
    "\n",
    "all_tasks = df.groupby(\"Task\").aggregate({\"onet_weight\":\"sum\"}).reset_index()\n",
    "task_statements = pd.read_csv(\"../input/onet/Task Statements.csv\")[[\"Task\",\"Title\"]]\n",
    "all_tasks = all_tasks.merge(task_statements, on=[\"Task\"], how=\"outer\")\n",
    "onet_occ = pd.read_csv(\"../input/onet/Occupation Data.csv\")[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "onet_occ.columns = [\"Detailed Occupation\",\"onet_title\"]\n",
    "onet_occ[\"Detailed Occupation\"] = onet_occ[\"Detailed Occupation\"].apply(lambda x: x[:-3])\n",
    "all_tasks = all_tasks.merge(onet_occ, left_on=\"Title\",right_on=\"onet_title\").drop(columns=[\"Title\"])\n",
    "\n",
    "all_tasks = all_tasks.replace(np.nan,0)\n",
    "perc_of_10K = (wage_employment.groupby(\"Detailed Occupation\")[\"TOT_EMP_US\"].first()/wage_employment[\"TOT_EMP_US\"].sum() * 10000).reset_index() # num of people for every 10K workers\n",
    "perc_of_10K = perc_of_10K.rename({\"TOT_EMP_US\":\"Percent of 10K workers\"},axis=1)\n",
    "\n",
    "\n",
    "all_tasks = all_tasks.merge(perc_of_10K, on=\"Detailed Occupation\")\n",
    "ratios = all_tasks['onet_weight'] / all_tasks['Percent of 10K workers']\n",
    "all_tasks[\"automated_weight\"] = np.minimum(ratios, 1)\n",
    "\n",
    "\n",
    "all_occupations = all_tasks.groupby(\"Detailed Occupation\").aggregate({\"automated_weight\":\"sum\",\"Task\":\"count\", \"onet_title\":\"first\"})\n",
    "all_occupations.columns = [\"occupation_# tasks automated\",\"occupation_# of tasks\",\"onet_title\"]\n",
    "all_occupations[\"occupation_onet_rating\"] = all_occupations[\"occupation_# tasks automated\"]/all_occupations[\"occupation_# of tasks\"]\n",
    "df = df.merge(all_tasks[[\"Task\",\"automated_weight\",\"Percent of 10K workers\"]], on=\"Task\")\n",
    "df = df.merge(all_occupations,on=[\"Detailed Occupation\",\"onet_title\"])\n",
    "\n",
    "df = df.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_occupations = all_occupations.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.rename({\"Title\":\"onet_title\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09a56d83-1460-4547-9f46-ce0baaa464ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O*NET-SOC Code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Element ID</th>\n",
       "      <th>Element Name</th>\n",
       "      <th>Scale ID</th>\n",
       "      <th>Scale Name</th>\n",
       "      <th>Data Value</th>\n",
       "      <th>N</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Lower CI Bound</th>\n",
       "      <th>Upper CI Bound</th>\n",
       "      <th>Recommend Suppress</th>\n",
       "      <th>Not Relevant</th>\n",
       "      <th>Date</th>\n",
       "      <th>Domain Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>2.A.1.a</td>\n",
       "      <td>Reading Comprehension</td>\n",
       "      <td>IM</td>\n",
       "      <td>Importance</td>\n",
       "      <td>4.12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.37</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>2.A.1.a</td>\n",
       "      <td>Reading Comprehension</td>\n",
       "      <td>LV</td>\n",
       "      <td>Level</td>\n",
       "      <td>4.75</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.07</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>2.A.1.b</td>\n",
       "      <td>Active Listening</td>\n",
       "      <td>IM</td>\n",
       "      <td>Importance</td>\n",
       "      <td>4.12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.88</td>\n",
       "      <td>4.37</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>2.A.1.b</td>\n",
       "      <td>Active Listening</td>\n",
       "      <td>LV</td>\n",
       "      <td>Level</td>\n",
       "      <td>4.88</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.32</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-1011.00</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>2.A.1.c</td>\n",
       "      <td>Writing</td>\n",
       "      <td>IM</td>\n",
       "      <td>Importance</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/2014</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61105</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>2.B.5.b</td>\n",
       "      <td>Management of Financial Resources</td>\n",
       "      <td>LV</td>\n",
       "      <td>Level</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.37</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61106</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>2.B.5.c</td>\n",
       "      <td>Management of Material Resources</td>\n",
       "      <td>IM</td>\n",
       "      <td>Importance</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61107</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>2.B.5.c</td>\n",
       "      <td>Management of Material Resources</td>\n",
       "      <td>LV</td>\n",
       "      <td>Level</td>\n",
       "      <td>1.88</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.12</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61108</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>2.B.5.d</td>\n",
       "      <td>Management of Personnel Resources</td>\n",
       "      <td>IM</td>\n",
       "      <td>Importance</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.63</td>\n",
       "      <td>3.12</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61109</th>\n",
       "      <td>53-7121.00</td>\n",
       "      <td>Tank Car, Truck, and Ship Loaders</td>\n",
       "      <td>2.B.5.d</td>\n",
       "      <td>Management of Personnel Resources</td>\n",
       "      <td>LV</td>\n",
       "      <td>Level</td>\n",
       "      <td>2.75</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.07</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>08/2019</td>\n",
       "      <td>Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61110 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      O*NET-SOC Code                              Title Element ID  \\\n",
       "0         11-1011.00                   Chief Executives    2.A.1.a   \n",
       "1         11-1011.00                   Chief Executives    2.A.1.a   \n",
       "2         11-1011.00                   Chief Executives    2.A.1.b   \n",
       "3         11-1011.00                   Chief Executives    2.A.1.b   \n",
       "4         11-1011.00                   Chief Executives    2.A.1.c   \n",
       "...              ...                                ...        ...   \n",
       "61105     53-7121.00  Tank Car, Truck, and Ship Loaders    2.B.5.b   \n",
       "61106     53-7121.00  Tank Car, Truck, and Ship Loaders    2.B.5.c   \n",
       "61107     53-7121.00  Tank Car, Truck, and Ship Loaders    2.B.5.c   \n",
       "61108     53-7121.00  Tank Car, Truck, and Ship Loaders    2.B.5.d   \n",
       "61109     53-7121.00  Tank Car, Truck, and Ship Loaders    2.B.5.d   \n",
       "\n",
       "                            Element Name Scale ID  Scale Name  Data Value  \\\n",
       "0                  Reading Comprehension       IM  Importance        4.12   \n",
       "1                  Reading Comprehension       LV       Level        4.75   \n",
       "2                       Active Listening       IM  Importance        4.12   \n",
       "3                       Active Listening       LV       Level        4.88   \n",
       "4                                Writing       IM  Importance        4.00   \n",
       "...                                  ...      ...         ...         ...   \n",
       "61105  Management of Financial Resources       LV       Level        1.12   \n",
       "61106   Management of Material Resources       IM  Importance        2.00   \n",
       "61107   Management of Material Resources       LV       Level        1.88   \n",
       "61108  Management of Personnel Resources       IM  Importance        2.88   \n",
       "61109  Management of Personnel Resources       LV       Level        2.75   \n",
       "\n",
       "         N  Standard Error  Lower CI Bound  Upper CI Bound Recommend Suppress  \\\n",
       "0      8.0            0.13            3.88            4.37                  N   \n",
       "1      8.0            0.16            4.43            5.07                  N   \n",
       "2      8.0            0.13            3.88            4.37                  N   \n",
       "3      8.0            0.23            4.43            5.32                  N   \n",
       "4      8.0            0.00            4.00            4.00                  N   \n",
       "...    ...             ...             ...             ...                ...   \n",
       "61105  8.0            0.13            0.88            1.37                  N   \n",
       "61106  8.0            0.00            2.00            2.00                  N   \n",
       "61107  8.0            0.13            1.63            2.12                  N   \n",
       "61108  8.0            0.13            2.63            3.12                  N   \n",
       "61109  8.0            0.16            2.43            3.07                  N   \n",
       "\n",
       "      Not Relevant     Date Domain Source  \n",
       "0              NaN  07/2014       Analyst  \n",
       "1                N  07/2014       Analyst  \n",
       "2              NaN  07/2014       Analyst  \n",
       "3                N  07/2014       Analyst  \n",
       "4              NaN  07/2014       Analyst  \n",
       "...            ...      ...           ...  \n",
       "61105            N  08/2019       Analyst  \n",
       "61106          NaN  08/2019       Analyst  \n",
       "61107            N  08/2019       Analyst  \n",
       "61108          NaN  08/2019       Analyst  \n",
       "61109            N  08/2019       Analyst  \n",
       "\n",
       "[61110 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../input/onet/Skills.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af6771d-d4c5-49be-8efe-b8efa74599b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "234\n"
     ]
    }
   ],
   "source": [
    "dwa = pd.read_csv(\"../input/onet/Tasks to DWAs.csv\")[3:].reset_index(drop=True)\n",
    "dwa = dwa[[\"DWA ID\",\"DWA Title\",\"Task\"]]\n",
    "# dwa = dwa.rename({\"ID\":\"Task ID\"},axis=1)\n",
    "grouped = dwa.groupby(\"Task\").aggregate({\"DWA ID\":\"count\"}).apply(lambda x: 1/x).reset_index()\n",
    "grouped = grouped.rename({\"DWA ID\":\"dwa_count\"},axis=1)\n",
    "dwa = dwa.merge(grouped,on=\"Task\")\n",
    "dwa_ref = pd.read_csv(\"../input/onet/DWA Reference.csv\")[[\"Element Name\",\"DWA ID\"]]\n",
    "dwa_ref = dwa_ref.rename({\"Element Name\":\"activity\"},axis=1)\n",
    "\n",
    "tf = df.merge(dwa, on=\"Task\",how=\"left\")\n",
    "tf = tf.merge(dwa_ref, on=\"DWA ID\",how=\"left\")\n",
    "print(len(tf[tf[\"DWA ID\"].isnull()]))\n",
    "\n",
    "print(len(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d01bf1b-900e-4c30-9851-f45f4169e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skill_activity = pd.read_csv(\"../input/onet/Skills to Work Activities.csv\")[[\"Work Activities Element Name\", \"Skills Element Name\"]]\n",
    "# skill_activity.columns = [\"activity\", \"skill\"]\n",
    "# skill_activity[\"skill_activity\"] = skill_activity[\"skill\"]+\" \"+skill_activity[\"activity\"]\n",
    "# skill_activity = x_chat.run_batch_embeddings(skill_activity, \"activity\")\n",
    "# skill_activity = x_chat.run_batch_embeddings(skill_activity, \"skill\")\n",
    "# skill_activity = x_chat.run_batch_embeddings(skill_activity, \"skill_activity\")\n",
    "# skill_activity.to_csv(\"../input/onet/activity_skill_embeddings.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8234fc20-4e66-45bf-bbe0-6478f318a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bls(wage_employment,type):\n",
    "    wage_employment = wage_employment[wage_employment.O_GROUP == \"detailed\"]\n",
    "    wage_employment = wage_employment.rename({\"OCC_CODE\": \"Detailed Occupation\"}, axis=1)\n",
    "    wage_employment = wage_employment.replace(\"#\", np.nan).replace(r\"\\*+\", np.nan, regex=True).replace(\",\", \"\", regex=True)\n",
    "    wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]] = wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\", \"JOBS_1000\"]].astype(\"float\")\n",
    "    wage_employment[\"H_MEDIAN\"] = wage_employment[\"H_MEDIAN\"].round(0)\n",
    "    wage_employment = wage_employment[[\"AREA\",\"Detailed Occupation\",\"H_MEDIAN\",\"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]]\n",
    "    wage_employment.columns = [\"AREA\",\"Detailed Occupation\",\"H_MEDIAN_\"+type,\"A_MEDIAN_\"+type,\"TOT_EMP_\"+type, 'JOBS_1000_'+type]\n",
    "    return wage_employment\n",
    "\n",
    "\n",
    "nonmetro = pd.read_csv(\"../input/wage_employment_2022/rural2022.csv\")\n",
    "metro = pd.read_csv(\"../input/wage_employment_2022/metro2022.csv\")\n",
    "nonmetro = parse_bls(nonmetro,\"RURAL\")\n",
    "metro = parse_bls(metro,\"METRO\")\n",
    "\n",
    "#figures out how much to weight each area\n",
    "def calculate_weights(df,type):\n",
    "    grouped = df.groupby(\"Detailed Occupation\")[\"TOT_EMP_\"+type].sum().reset_index()\n",
    "    grouped = grouped.rename({\"TOT_EMP_\"+type: \"sum_\"+type}, axis=1)\n",
    "    df = df.merge(grouped, on=\"Detailed Occupation\")\n",
    "    df[\"weight_area_\"+type] = df[\"TOT_EMP_\"+type] / df[\"sum_\"+type]\n",
    "    df[\"weighted_JOBS_1000_\"+type] = df[\"JOBS_1000_\"+type]*df[\"weight_area_\"+type]\n",
    "    return df\n",
    "metro = calculate_weights(metro,\"METRO\")\n",
    "nonmetro = calculate_weights(nonmetro,\"RURAL\")\n",
    "\n",
    "metro_grouped = metro.groupby(\"Detailed Occupation\").aggregate({\"H_MEDIAN_METRO\":\"mean\",\"TOT_EMP_METRO\":\"sum\",\"A_MEDIAN_METRO\":\"mean\", \"weighted_JOBS_1000_METRO\":\"sum\"},axis=1).reset_index()\n",
    "nonmetro_grouped = nonmetro.groupby(\"Detailed Occupation\").aggregate({\"H_MEDIAN_RURAL\":\"mean\",\"TOT_EMP_RURAL\":\"sum\",\"A_MEDIAN_RURAL\":\"mean\",\"weighted_JOBS_1000_RURAL\":\"sum\"},axis=1).reset_index()\n",
    "\n",
    "df = df.merge(metro_grouped,on=\"Detailed Occupation\",how=\"left\")\n",
    "df = df.merge(nonmetro_grouped,on=\"Detailed Occupation\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce2c8caf-17ef-44d4-ad87-105763fee7cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/wage_employment_2022/area_definitions_m2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m locations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted_onet_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m locations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJOBS_1000\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39mlocations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moccupation_onet_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m locations \u001b[38;5;241m=\u001b[39m locations\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAREA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39maggregate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted_onet_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m----> 9\u001b[0m area_code \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/wage_employment_2022/area_definitions_m2022.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)[[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState abbreviation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMay 2022 MSA name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMay 2022 MSA code \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCounty name (or Township name for the New England states)\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     10\u001b[0m area_code\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplace\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAREA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m locations \u001b[38;5;241m=\u001b[39m locations\u001b[38;5;241m.\u001b[39mmerge(area_code, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAREA\u001b[39m\u001b[38;5;124m\"\u001b[39m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/wage_employment_2022/area_definitions_m2022.csv'"
     ]
    }
   ],
   "source": [
    "metro.columns = [col.replace(\"_METRO\",\"\") for col in metro.columns]\n",
    "metro[\"Type\"] = \"METRO\"\n",
    "nonmetro.columns = [col.replace(\"_RURAL\",\"\") for col in nonmetro.columns]\n",
    "nonmetro[\"Type\"] = \"RURAL\"\n",
    "locations = pd.concat([metro, nonmetro],axis=0)\n",
    "locations = locations.merge(all_occupations,on=\"Detailed Occupation\")\n",
    "locations[\"weighted_onet_rating\"] = locations[\"JOBS_1000\"]*locations[\"occupation_onet_rating\"]\n",
    "locations = locations.groupby(\"AREA\").aggregate({\"weighted_onet_rating\":\"sum\", \"Type\":\"first\"}).reset_index()\n",
    "area_code = pd.read_csv(\"../output/geography.csv\")[[\"AREA\", \"Latitude\",\"Longitude\",\"Boundary\"]]\n",
    "area_code.columns = [\"state\",\"place\",\"AREA\",\"name\"]\n",
    "locations = locations.merge(area_code, on=\"AREA\",how=\"left\")\n",
    "locations = locations.dropna(subset=[\"name\"])\n",
    "locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244a6fc7-4429-40f2-984f-964f214fc33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/50\n",
      "Processing batch 2/50\n",
      "Processing batch 3/50\n",
      "Processing batch 4/50\n",
      "Processing batch 5/50\n",
      "Processing batch 6/50\n",
      "Processing batch 7/50\n",
      "Processing batch 8/50\n",
      "Processing batch 9/50\n",
      "Processing batch 10/50\n",
      "Processing batch 11/50\n",
      "Processing batch 12/50\n",
      "Processing batch 13/50\n",
      "Processing batch 14/50\n",
      "Processing batch 15/50\n",
      "Processing batch 16/50\n",
      "Processing batch 17/50\n",
      "Processing batch 18/50\n",
      "Processing batch 19/50\n",
      "Processing batch 20/50\n",
      "Processing batch 21/50\n",
      "Processing batch 22/50\n",
      "Processing batch 23/50\n",
      "Processing batch 24/50\n",
      "Processing batch 25/50\n",
      "Processing batch 26/50\n",
      "Processing batch 27/50\n",
      "Processing batch 28/50\n",
      "Processing batch 29/50\n",
      "Processing batch 30/50\n",
      "Processing batch 31/50\n",
      "Processing batch 32/50\n",
      "Processing batch 33/50\n",
      "Processing batch 34/50\n",
      "Processing batch 35/50\n",
      "Processing batch 36/50\n",
      "Processing batch 37/50\n",
      "Processing batch 38/50\n",
      "Processing batch 39/50\n",
      "Processing batch 40/50\n",
      "Processing batch 41/50\n",
      "Processing batch 42/50\n",
      "Processing batch 43/50\n",
      "Processing batch 44/50\n",
      "Processing batch 45/50\n",
      "Processing batch 46/50\n",
      "Processing batch 47/50\n",
      "Processing batch 48/50\n",
      "Processing batch 49/50\n",
      "Processing batch 50/50\n"
     ]
    }
   ],
   "source": [
    "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load area_code dataframe\n",
    "area_code = pd.read_csv(\"../input/wage_employment_2022/area_definitions_m2022.csv\")[[ 'State abbreviation','May 2022 MSA name','May 2022 MSA code ','County name (or Township name for the New England states)']]\n",
    "area_code.columns = [\"state\", \"place\", \"AREA\", \"name\"]\n",
    "area_code[\"Latitude\"] = \"N/A\"\n",
    "area_code[\"Longitude\"] = \"N/A\"\n",
    "area_code[\"Boundary\"] = \"N/A\"\n",
    "\n",
    "async def get_lat_long(session, msa_name):\n",
    "    while True:\n",
    "        try:\n",
    "            url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={msa_name}&key={GEO_KEY}\"\n",
    "            async with session.get(url) as response:\n",
    "                while True:\n",
    "                    data = await response.json()\n",
    "                    if data['status'] == 'OK':\n",
    "                        bounds = data['results'][0]['geometry']\n",
    "                        location = data['results'][0]['geometry']['location']\n",
    "                        return location['lat'], location['lng'], bounds\n",
    "                    else:\n",
    "                        if data['status'] != \"OVER_QUERY_LIMIT\":\n",
    "                            return None, None, None\n",
    "                        print(f\"Geocoding error for {msa_name}: {data['status']}\")\n",
    "                        await asyncio.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding {msa_name}: {e}\")\n",
    "            return None, None, None\n",
    "\n",
    "# Define the main asynchronous function\n",
    "async def process_area_code_batch(area_code_batch):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for index, row in area_code_batch.iterrows():\n",
    "            msa_name = row['name'] + \" \" + row[\"state\"]\n",
    "            tasks.append(get_lat_long(session, msa_name))\n",
    "        \n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        for (index, (lat, lng, bounds)) in zip(area_code_batch.index, results):\n",
    "            area_code_batch.at[index, 'Latitude'] = lat\n",
    "            area_code_batch.at[index, 'Longitude'] = lng\n",
    "            area_code_batch.at[index, 'Boundary'] = bounds\n",
    "\n",
    "    return area_code_batch\n",
    "\n",
    "# Function to process the entire DataFrame in batches\n",
    "async def process_area_code_in_batches(area_code, batch_size=100):\n",
    "    batches = [area_code.iloc[i:i + batch_size] for i in range(0, len(area_code), batch_size)]\n",
    "    results = []\n",
    "    for i, batch in enumerate(batches):\n",
    "        print(f\"Processing batch {i + 1}/{len(batches)}\")\n",
    "        result_batch = await process_area_code_batch(batch)\n",
    "        results.append(result_batch)\n",
    "        await asyncio.sleep(10)\n",
    "    return pd.concat(results)\n",
    "\n",
    "\n",
    "area_code = await process_area_code_in_batches(area_code, batch_size=100)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5192347f-ca64-44d7-984b-fdf7dd33f017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>place</th>\n",
       "      <th>AREA</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Montgomery, AL</td>\n",
       "      <td>33860</td>\n",
       "      <td>Autauga County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Daphne-Fairhope-Foley, AL</td>\n",
       "      <td>19300</td>\n",
       "      <td>Baldwin County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Southeast Alabama nonmetropolitan area</td>\n",
       "      <td>100004</td>\n",
       "      <td>Barbour County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>13820</td>\n",
       "      <td>Bibb County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>Birmingham-Hoover, AL</td>\n",
       "      <td>13820</td>\n",
       "      <td>Blount County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>PR</td>\n",
       "      <td>San Juan-Carolina-Caguas, PR</td>\n",
       "      <td>41980</td>\n",
       "      <td>Vega Baja Municipio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>PR</td>\n",
       "      <td>Puerto Rico nonmetropolitan area</td>\n",
       "      <td>7200006</td>\n",
       "      <td>Vieques</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>PR</td>\n",
       "      <td>Ponce, PR</td>\n",
       "      <td>38660</td>\n",
       "      <td>Villalba Municipio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>PR</td>\n",
       "      <td>San Juan-Carolina-Caguas, PR</td>\n",
       "      <td>41980</td>\n",
       "      <td>Yabucoa Municipio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>PR</td>\n",
       "      <td>Ponce, PR</td>\n",
       "      <td>38660</td>\n",
       "      <td>Yauco Municipio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state                                   place     AREA  \\\n",
       "0       AL                          Montgomery, AL    33860   \n",
       "1       AL               Daphne-Fairhope-Foley, AL    19300   \n",
       "2       AL  Southeast Alabama nonmetropolitan area   100004   \n",
       "3       AL                   Birmingham-Hoover, AL    13820   \n",
       "4       AL                   Birmingham-Hoover, AL    13820   \n",
       "...    ...                                     ...      ...   \n",
       "4932    PR            San Juan-Carolina-Caguas, PR    41980   \n",
       "4933    PR        Puerto Rico nonmetropolitan area  7200006   \n",
       "4934    PR                               Ponce, PR    38660   \n",
       "4935    PR            San Juan-Carolina-Caguas, PR    41980   \n",
       "4936    PR                               Ponce, PR    38660   \n",
       "\n",
       "                     name  \n",
       "0          Autauga County  \n",
       "1          Baldwin County  \n",
       "2          Barbour County  \n",
       "3             Bibb County  \n",
       "4           Blount County  \n",
       "...                   ...  \n",
       "4932  Vega Baja Municipio  \n",
       "4933              Vieques  \n",
       "4934   Villalba Municipio  \n",
       "4935    Yabucoa Municipio  \n",
       "4936      Yauco Municipio  \n",
       "\n",
       "[4937 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ac0e9-5c1d-4e98-b0bd-d89c305b7ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
