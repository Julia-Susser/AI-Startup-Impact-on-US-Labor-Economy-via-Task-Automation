{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51515061-2e5c-4156-9abd-dc586ed2db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from llms import gemini\n",
    "from llms import chatGPT\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plotting\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.utils import ImageReader\n",
    "import plotly.io as pio\n",
    "import os\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import ast\n",
    "\n",
    "x_chat = chatGPT()\n",
    "x_gemini = gemini()\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(\"../.env\",override=True)\n",
    "GEO_KEY = getenv(\"geo_api_key\")\n",
    "\n",
    "df = pd.read_csv(\"../output/bls_df.csv\",index_col=0)\n",
    "tsne = pd.read_csv(\"../output/tsne.csv\",index_col=0)\n",
    "df = pd.concat([df,tsne],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2fab82-318d-42ab-8d08-aaf0b872c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wage_employment = pd.read_csv(\"../input/wage_employment2022/national2022.csv\")\n",
    "wage_employment = wage_employment[wage_employment.O_GROUP == \"detailed\"]\n",
    "wage_employment = wage_employment.rename({\"OCC_CODE\": \"Detailed Occupation\"}, axis=1)\n",
    "wage_employment = wage_employment.replace(\"#\", np.nan).replace(\"*\", np.nan).replace({\",\": \"\"}, regex=True)\n",
    "wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]] = wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]].astype(\"float\")\n",
    "wage_employment[\"H_MEDIAN\"] = wage_employment[\"H_MEDIAN\"].round(0)\n",
    "wage_employment = wage_employment[[\"Detailed Occupation\",\"H_MEDIAN\",\"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]]\n",
    "wage_employment.columns = [\"Detailed Occupation\",\"H_MEDIAN_US\",\"A_MEDIAN_US\",\"TOT_EMP_US\",\"JOBS_1000_US\"]\n",
    "\n",
    "\n",
    "all_tasks = df.groupby(\"Task\").aggregate({\"onet_weight\":\"sum\"}).reset_index()\n",
    "task_statements = pd.read_csv(\"../input/onet/Task Statements.csv\")[[\"Task\",\"Title\"]]\n",
    "all_tasks = all_tasks.merge(task_statements, on=[\"Task\"], how=\"outer\")\n",
    "onet_occ = pd.read_csv(\"../input/onet/Occupation Data.csv\")[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "onet_occ.columns = [\"Detailed Occupation\",\"onet_title\"]\n",
    "onet_occ[\"Detailed Occupation\"] = onet_occ[\"Detailed Occupation\"].apply(lambda x: x[:-3])\n",
    "all_tasks = all_tasks.merge(onet_occ, left_on=\"Title\",right_on=\"onet_title\").drop(columns=[\"Title\"])\n",
    "\n",
    "all_tasks = all_tasks.replace(np.nan,0)\n",
    "perc_of_10K = (wage_employment.groupby(\"Detailed Occupation\")[\"TOT_EMP_US\"].first()/df[\"TOT_EMP_US\"].sum() * 10000).reset_index() # num of people for every 10K workers\n",
    "perc_of_10K = perc_of_10K.rename({\"TOT_EMP_US\":\"Percent of 10K workers\"},axis=1)\n",
    "\n",
    "\n",
    "all_tasks = all_tasks.merge(perc_of_10K, on=\"Detailed Occupation\")\n",
    "ratios = all_tasks['onet_weight'] / all_tasks['Percent of 10K workers']\n",
    "all_tasks[\"automated_weight\"] = np.minimum(ratios, 1)\n",
    "\n",
    "\n",
    "all_occupations = all_tasks.groupby(\"Detailed Occupation\").aggregate({\"automated_weight\":\"sum\",\"Task\":\"count\", \"onet_title\":\"first\"})\n",
    "all_occupations.columns = [\"occupation_# tasks automated\",\"occupation_# of tasks\",\"onet_title\"]\n",
    "all_occupations[\"occupation_onet_rating\"] = all_occupations[\"occupation_# tasks automated\"]/all_occupations[\"occupation_# of tasks\"]\n",
    "df = df.merge(all_tasks[[\"Task\",\"automated_weight\",\"Percent of 10K workers\"]], on=\"Task\")\n",
    "df = df.merge(all_occupations,on=[\"Detailed Occupation\",\"onet_title\"])\n",
    "\n",
    "\n",
    "\n",
    "all_occupations = all_occupations.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.rename({\"Title\":\"onet_title\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a0489-ebbe-473c-8e2c-cf2d8adac01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv(\"../input/soc_codes/soc_codes.csv\", index_col=0)\n",
    "all_occupations = all_occupations.merge(codes,on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.merge(codes,on=\"Detailed Occupation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f76afd-a160-44bc-804a-4348e33cfa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwa = pd.read_csv(\"../input/onet/Tasks to DWAs.csv\")[3:].reset_index(drop=True)\n",
    "dwa = dwa[[\"DWA ID\",\"DWA Title\",\"Task\"]]\n",
    "# dwa = dwa.rename({\"ID\":\"Task ID\"},axis=1)\n",
    "grouped = dwa.groupby(\"Task\").aggregate({\"DWA ID\":\"count\"}).apply(lambda x: 1/x).reset_index()\n",
    "grouped = grouped.rename({\"DWA ID\":\"dwa_count\"},axis=1)\n",
    "dwa = dwa.merge(grouped,on=\"Task\")\n",
    "dwa_ref = pd.read_csv(\"../input/onet/DWA Reference.csv\")[[\"Element Name\",\"DWA ID\"]]\n",
    "dwa_ref = dwa_ref.rename({\"Element Name\":\"activity\"},axis=1)\n",
    "\n",
    "tf = df.merge(dwa, on=\"Task\",how=\"left\")\n",
    "tf = tf.merge(dwa_ref, on=\"DWA ID\",how=\"left\")\n",
    "print(len(tf[tf[\"DWA ID\"].isnull()]))\n",
    "\n",
    "print(len(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf94a8b-1c0a-48d6-af18-a6a895a901cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bls(wage_employment,type):\n",
    "    wage_employment = wage_employment[wage_employment.O_GROUP == \"detailed\"]\n",
    "    wage_employment = wage_employment.rename({\"OCC_CODE\": \"Detailed Occupation\"}, axis=1)\n",
    "    wage_employment = wage_employment.replace(\"#\", np.nan).replace(r\"\\*+\", np.nan, regex=True).replace(\",\", \"\", regex=True)\n",
    "    wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]] = wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\", \"JOBS_1000\"]].astype(\"float\")\n",
    "    wage_employment[\"H_MEDIAN\"] = wage_employment[\"H_MEDIAN\"].round(0)\n",
    "    wage_employment = wage_employment[[\"AREA\",\"Detailed Occupation\",\"H_MEDIAN\",\"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]]\n",
    "    wage_employment.columns = [\"AREA\",\"Detailed Occupation\",\"H_MEDIAN_\"+type,\"A_MEDIAN_\"+type,\"TOT_EMP_\"+type, 'JOBS_1000_'+type]\n",
    "    return wage_employment\n",
    "\n",
    "\n",
    "nonmetro = pd.read_csv(\"../input/wage_employment2022/non-metro.csv\")\n",
    "metro = pd.read_csv(\"../input/wage_employment2022/metro.csv\")\n",
    "nonmetro = parse_bls(nonmetro,\"RURAL\")\n",
    "metro = parse_bls(metro,\"METRO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783ccb0-2e84-4f9d-a60a-75c11b206bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figures out how much to weight each area\n",
    "def calculate_weights(df,type):\n",
    "    grouped = df.groupby(\"Detailed Occupation\")[\"TOT_EMP_\"+type].sum().reset_index()\n",
    "    grouped = grouped.rename({\"TOT_EMP_\"+type: \"sum_\"+type}, axis=1)\n",
    "    df = df.merge(grouped, on=\"Detailed Occupation\")\n",
    "    df[\"weight_area_\"+type] = df[\"TOT_EMP_\"+type] / df[\"sum_\"+type]\n",
    "    df[\"weighted_JOBS_1000_\"+type] = df[\"JOBS_1000_\"+type]*df[\"weight_area_\"+type]\n",
    "    return df\n",
    "metro = calculate_weights(metro,\"METRO\")\n",
    "nonmetro = calculate_weights(nonmetro,\"RURAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b1f7b-bd9d-4572-afd2-faa33d7ffd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_grouped = metro.groupby(\"Detailed Occupation\").aggregate({\"H_MEDIAN_METRO\":\"mean\",\"TOT_EMP_METRO\":\"sum\",\"A_MEDIAN_METRO\":\"mean\", \"weighted_JOBS_1000_METRO\":\"sum\"},axis=1).reset_index()\n",
    "nonmetro_grouped = nonmetro.groupby(\"Detailed Occupation\").aggregate({\"H_MEDIAN_RURAL\":\"mean\",\"TOT_EMP_RURAL\":\"sum\",\"A_MEDIAN_RURAL\":\"mean\",\"weighted_JOBS_1000_RURAL\":\"sum\"},axis=1).reset_index()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
