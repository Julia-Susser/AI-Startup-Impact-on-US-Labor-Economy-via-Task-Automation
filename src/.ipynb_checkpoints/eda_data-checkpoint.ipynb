{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "51515061-2e5c-4156-9abd-dc586ed2db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from llms import gemini\n",
    "from llms import chatGPT\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plotting\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.utils import ImageReader\n",
    "import plotly.io as pio\n",
    "import requests\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import os\n",
    "from os import getenv\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import ast \n",
    "\n",
    "load_dotenv(\"../.env\",override=True)\n",
    "GEO_KEY = getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "x_chat = chatGPT()\n",
    "x_gemini = gemini()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70f05d31-a8d6-45bc-a67e-dad5f4072555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../output/results/bls_df.csv\",index_col=0)\n",
    "tsne = pd.read_csv(\"../output/results/tsne.csv\",index_col=0)\n",
    "df = pd.concat([df,tsne],axis=1)\n",
    "\n",
    "# df.example_task_embedding = df.example_task_embedding.apply(lambda x: [float(y) for y in x.strip(\"[]\").split(\", \")])\n",
    "# df.onet_task_embedding = df.onet_task_embedding.apply(lambda x: [float(y) for y in x.strip(\"[]\").split(\", \")])\n",
    "# df.onet_title_embedding = df.onet_title_embedding.apply(lambda x: [float(y) for y in x.strip(\"[]\").split(\", \")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4f189805-04e9-4239-9d0c-5228147a635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a891112f-ee96-45ae-988a-64594ce4f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "onet_occ = pd.read_csv(\"../input/onet/Occupation Data.csv\")[[\"O*NET-SOC Code\",\"Title\"]]\n",
    "onet_occ.columns = [\"Detailed Occupation\",\"onet_title\"]\n",
    "onet_occ[\"Detailed Occupation\"] = onet_occ[\"Detailed Occupation\"].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e80ca9ad-9524-4f8c-8fd7-51ab7e23e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wage_employment = pd.read_csv(\"../input/wage_employment_2022/national2022.csv\")\n",
    "wage_employment = wage_employment[wage_employment.O_GROUP == \"detailed\"]\n",
    "wage_employment = wage_employment.rename({\"OCC_CODE\": \"Detailed Occupation\"}, axis=1)\n",
    "wage_employment = wage_employment.replace(\"#\", np.nan).replace(\"*\", np.nan).replace({\",\": \"\"}, regex=True)\n",
    "wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\"]] = wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\"]].astype(\"float\")\n",
    "wage_employment[\"H_MEDIAN\"] = wage_employment[\"H_MEDIAN\"].round(0)\n",
    "wage_employment = wage_employment[[\"Detailed Occupation\",\"H_MEDIAN\",\"A_MEDIAN\",\"TOT_EMP\"]]\n",
    "wage_employment.columns = [\"Detailed Occupation\",\"H_MEDIAN_US\",\"A_MEDIAN_US\",\"TOT_EMP_US\"]\n",
    "\n",
    "\n",
    "all_tasks = df.groupby([\"Task\",\"Title\"]).aggregate({\"onet_weight\":\"sum\"}).reset_index()\n",
    "task_statements = pd.read_csv(\"../input/onet/Task Statements.csv\")[[\"Task\",\"Title\"]]\n",
    "all_tasks = all_tasks.merge(task_statements, on=[\"Task\",\"Title\"], how=\"outer\")\n",
    "all_tasks = all_tasks.merge(onet_occ, left_on=\"Title\",right_on=\"onet_title\").drop(columns=[\"Title\"])\n",
    "\n",
    "all_tasks = all_tasks.replace(np.nan,0)\n",
    "perc_of_10K = (wage_employment.groupby(\"Detailed Occupation\")[\"TOT_EMP_US\"].first()/wage_employment[\"TOT_EMP_US\"].sum()).reset_index() # num of people for every 10K workers\n",
    "perc_of_10K = perc_of_10K.rename({\"TOT_EMP_US\":\"Percent of 10K workers\"},axis=1)\n",
    "\n",
    "\n",
    "all_tasks = all_tasks.merge(perc_of_10K, on=\"Detailed Occupation\")\n",
    "ratios = all_tasks['onet_weight'] / all_tasks['Percent of 10K workers']\n",
    "all_tasks[\"task_automation_rating\"] = np.minimum(ratios, 1)\n",
    "\n",
    "\n",
    "all_occupations = all_tasks.groupby(\"Detailed Occupation\").aggregate({\"task_automation_rating\":\"sum\",\"Task\":\"count\", \"onet_title\":\"first\"})\n",
    "all_occupations.columns = [\"occupation_# tasks automated\",\"occupation_# of tasks\",\"onet_title\"]\n",
    "all_occupations[\"occupation_automation_rating\"] = all_occupations[\"occupation_# tasks automated\"]/all_occupations[\"occupation_# of tasks\"]\n",
    "df = df.merge(all_tasks[[\"Task\",\"onet_title\",\"task_automation_rating\",\"Percent of 10K workers\"]], on=[\"Task\",\"onet_title\"], how=\"left\")\n",
    "df = df.merge(all_occupations,on=[\"Detailed Occupation\",\"onet_title\"],how=\"left\")\n",
    "\n",
    "df = df.merge(wage_employment, on=\"Detailed Occupation\", how=\"left\")\n",
    "all_occupations = all_occupations.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.merge(wage_employment, on=\"Detailed Occupation\")\n",
    "all_tasks = all_tasks.rename({\"Title\":\"onet_title\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "abb57be9-4523-49c7-81aa-df1bcba49398",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_zones = pd.read_csv(\"../input/onet/Job Zones.csv\",index_col=0)[[\"Title\",\"Job Zone\"]]\n",
    "job_zones_ref = pd.read_csv(\"../input/onet/Job Zone Reference.csv\",index_col=0)\n",
    "df = df.merge(job_zones, on=\"Title\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0da261fd-7258-4c3d-8a7c-aa8e542fe098",
   "metadata": {},
   "outputs": [],
   "source": [
    "education = pd.read_csv(\"../input/onet/Education, Training, and Experience.csv\")[[\"Title\",\"Data Value\",\"Category\", \"Scale Name\"]]\n",
    "education[\"weighted_category\"] = education[\"Data Value\"]/100*education[\"Category\"]\n",
    "education = education.groupby([\"Title\",\"Scale Name\"])[\"weighted_category\"].sum().reset_index()\n",
    "education = education.pivot(index=['Title'], columns='Scale Name', values='weighted_category').reset_index().drop(columns=[\"Importance\"])\n",
    "education.columns.name = None\n",
    "education.columns = [col if not isinstance(col, tuple) else col[1] for col in education.columns]\n",
    "df = df.merge(education, on=\"Title\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1af6771d-d4c5-49be-8efe-b8efa74599b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "54079\n"
     ]
    }
   ],
   "source": [
    "dwa = pd.read_csv(\"../input/onet/Tasks to DWAs.csv\")[3:].reset_index(drop=True)\n",
    "dwa = dwa[[\"DWA ID\",\"DWA Title\",\"Task\"]]\n",
    "# dwa = dwa.rename({\"ID\":\"Task ID\"},axis=1)\n",
    "grouped = dwa.groupby(\"Task\").aggregate({\"DWA ID\":\"count\"}).apply(lambda x: 1/x).reset_index()\n",
    "grouped = grouped.rename({\"DWA ID\":\"dwa_count\"},axis=1)\n",
    "dwa = dwa.merge(grouped,on=\"Task\")\n",
    "dwa_ref = pd.read_csv(\"../input/onet/DWA Reference.csv\")[[\"Element Name\",\"DWA ID\"]]\n",
    "dwa_ref = dwa_ref.rename({\"Element Name\":\"activity\"},axis=1)\n",
    "\n",
    "df_activity = df.merge(dwa, on=\"Task\",how=\"left\")\n",
    "df_activity = df_activity.merge(dwa_ref, on=\"DWA ID\",how=\"left\")\n",
    "print(len(df_activity[df_activity[\"DWA ID\"].isnull()]))\n",
    "\n",
    "print(len(df_activity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d62dff45-e26d-4dc2-8427-6675dd93f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks_activity = all_tasks.merge(dwa, on=\"Task\",how=\"left\")\n",
    "all_tasks_activity = all_tasks_activity.merge(dwa_ref, on=\"DWA ID\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8234fc20-4e66-45bf-bbe0-6478f318a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bls(wage_employment,type):\n",
    "    wage_employment = wage_employment[wage_employment.O_GROUP == \"detailed\"]\n",
    "    wage_employment = wage_employment.rename({\"OCC_CODE\": \"Detailed Occupation\"}, axis=1)\n",
    "    wage_employment = wage_employment.replace(\"#\", np.nan).replace(r\"\\*+\", np.nan, regex=True).replace(\",\", \"\", regex=True)\n",
    "    wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]] = wage_employment[[\"H_MEDIAN\", \"A_MEDIAN\",\"TOT_EMP\", \"JOBS_1000\"]].astype(\"float\")\n",
    "    wage_employment[\"H_MEDIAN\"] = wage_employment[\"H_MEDIAN\"].round(0)\n",
    "    wage_employment = wage_employment[[\"AREA\",\"Detailed Occupation\",\"H_MEDIAN\",\"A_MEDIAN\",\"TOT_EMP\",\"JOBS_1000\"]]\n",
    "    wage_employment.columns = [\"AREA\",\"Detailed Occupation\",\"H_MEDIAN_\"+type,\"A_MEDIAN_\"+type,\"TOT_EMP_\"+type, 'JOBS_1000_'+type]\n",
    "    return wage_employment\n",
    "\n",
    "\n",
    "nonmetro = pd.read_csv(\"../input/wage_employment_2022/rural2022.csv\")\n",
    "metro = pd.read_csv(\"../input/wage_employment_2022/metro2022.csv\")\n",
    "nonmetro = parse_bls(nonmetro,\"RURAL\")\n",
    "metro = parse_bls(metro,\"METRO\")\n",
    "\n",
    "#figures out how much to weight each area\n",
    "def calculate_weights(df,type):\n",
    "    grouped = df.groupby(\"Detailed Occupation\")[\"TOT_EMP_\"+type].sum().reset_index()\n",
    "    grouped = grouped.rename({\"TOT_EMP_\"+type: \"sum_\"+type}, axis=1)\n",
    "    df = df.merge(grouped, on=\"Detailed Occupation\")\n",
    "    df[\"weight_area_\"+type] = df[\"TOT_EMP_\"+type] / df[\"sum_\"+type]\n",
    "    df[\"weighted_JOBS_1000_\"+type] = df[\"JOBS_1000_\"+type]*df[\"weight_area_\"+type]\n",
    "    return df\n",
    "metro = calculate_weights(metro,\"METRO\")\n",
    "nonmetro = calculate_weights(nonmetro,\"RURAL\")\n",
    "\n",
    "metro_grouped = metro.groupby(\"Detailed Occupation\").aggregate({\"H_MEDIAN_METRO\":\"mean\",\"TOT_EMP_METRO\":\"sum\",\"A_MEDIAN_METRO\":\"mean\", \"weighted_JOBS_1000_METRO\":\"sum\"},axis=1).reset_index()\n",
    "nonmetro_grouped = nonmetro.groupby(\"Detailed Occupation\").aggregate({\"H_MEDIAN_RURAL\":\"mean\",\"TOT_EMP_RURAL\":\"sum\",\"A_MEDIAN_RURAL\":\"mean\",\"weighted_JOBS_1000_RURAL\":\"sum\"},axis=1).reset_index()\n",
    "\n",
    "df = df.merge(metro_grouped,on=\"Detailed Occupation\",how=\"left\")\n",
    "df = df.merge(nonmetro_grouped,on=\"Detailed Occupation\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ce2c8caf-17ef-44d4-ad87-105763fee7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro.columns = [col.replace(\"_METRO\",\"\") for col in metro.columns]\n",
    "metro[\"Type\"] = \"METRO\"\n",
    "nonmetro.columns = [col.replace(\"_RURAL\",\"\") for col in nonmetro.columns]\n",
    "nonmetro[\"Type\"] = \"RURAL\"\n",
    "locations = pd.concat([metro, nonmetro],axis=0)\n",
    "locations = locations.merge(all_occupations,on=\"Detailed Occupation\")\n",
    "locations[\"weighted_automation_#_per_1000_people\"] = locations[\"JOBS_1000\"]*locations[\"occupation_automation_rating\"]\n",
    "locations = locations.groupby(\"AREA\").aggregate({\"weighted_automation_#_per_1000_people\":\"sum\", \"Type\":\"first\"}).reset_index()\n",
    "\n",
    "\n",
    "geo = pd.read_csv(\"../output/parsed_BLS_data/geography.csv\",index_col=0)\n",
    "geo.Boundary = geo.Boundary.apply(lambda x: ast.literal_eval(x) if not pd.isnull(x) else x)\n",
    "geo = geo[~geo[\"name\"].str.contains(\"Census Area\")]\n",
    "\n",
    "\n",
    "locations = locations.merge(geo, on=\"AREA\",how=\"left\")\n",
    "locations = locations.dropna(subset=[\"name\"])\n",
    "\n",
    "locations.to_csv(\"../output/EDA_data/automation_by_geography.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "775ac0e9-5c1d-4e98-b0bd-d89c305b7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occupations.to_csv(\"../output/EDA_data/all_occupations_automation.csv\")\n",
    "all_tasks.to_csv(\"../output/EDA_data/all_tasks_automation.csv\")\n",
    "df.to_csv(\"../output/EDA_data/startup_data.csv\")\n",
    "df_activity.to_csv(\"../output/EDA_data/startup_data_with_activities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bda1ffc0-886a-4a85-895a-6ec491bfb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks_activity.to_csv(\"../output/EDA_data/all_tasks_automation_activity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ba438-cd53-4071-b425-ac2a29ac37a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
